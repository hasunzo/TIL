## 애플리케이션 커뮤니케이션
### 동기 커뮤니케이션
- 애플리케이션이 또 다른 애플리케이션과 직접적으로 연결
- 구매 서비스가 배송 서비스에게 사건이 발생했으니 배송을 하라고 얘기
### 비동기 커뮤니케이션
- 대기열 등으로 불리는 미들웨어가 애플리케이션들을 연결
- 구매 서비스가 '누군가가 어떤 물건을 구매했으니 이를 대기열에 포함시키겠다' 라고 하고 끝
- 그러면 배송 서비스가 대기열에게 최근 구매 내역이 있는지 물어보고
- 대기열이 해당 요소를 반환하면 배송 서비스는 자기가 원하는 것을 무엇이든지 할 수 있음
- 구매 서비스와 배송 서비스가 직접적으로 연결되어 있지 않음
- 그 사이에 대기열이 있을 뿐.
### 동기화가 문제가 되는 경우
- 구매가 갑자기 너무 증가
- 한 서비스가 다른 서비스를 압도
- 트래픽이 갑자기 급증하거나 아무것도 예측할 수 없을 때 일반적으로 애플리케이션을 분리하고 분리 계층을 확장하는 것이 좋음
- 대기열 모델 : SQS
- pub/sub 모델 : SNS
- 실시간 스트리밍, 대용량 데이터 : Kinesis


## SQS
- AWS에서 가장 오래된 서비스
- 간단한 대기 서비스
- SQS 대기열에는 메시지를 포함
- 메시지를 담기 위해서는 무언가 SQS 대기열에 메시지를 전송해야 하는데,
- 대기열에 메시지를 보내는 주체 : 생산자
  - 여러 생산자가 여러 개의 메시지를 SQS 대기열에 보내게 할 수 있음
- 메시지를 수신하는 대상 : 소비자
  - 소비자는 대기열에서 메시지를 폴링함
  - 이는 대기열에게 소비자 앞으로 온 메시지가 있는지를 물어보는 것
  - 만일 대기열에 메시지가 있으면 소비자는 이 메시지를 폴링해서 정보를 얻음
  - 그리고 그 메시지로 처리를 하고 대기열에서 해당 메시지를 삭제함
  - 여러 소비자가 SQS 대기열에서 메시지를 소비할 수 있도록 할 수도 있음
- 대기열 서비스는 생산자와 소비자 사이를 분리하는 버퍼 약할을 함
- 애플리케이션 분리에 대한 문제가 보이면 Amazon SQS 생각하기
### SQS의 특별한 점
- 무제한 처리량을 얻을 수 있음
- 초당 원하는 만큼 메시지를 보낼 수 있고 대기열에도 원하는 만큼 메시지를 포함시킬 수 있음
- 처리량에 제한이 없고 대기열에 있는 메시지 수에도 제한이 없음
- 각 메시지는 수명이 짧아, 대기열에 메시지를 보내자마자 소비자가 읽고 해당 보존기간 내에 처리 후 삭제해야 함
- 기본값은 4일, 최대 14일 동안 대기열에 있을 수 있음
- 지연 시간이 짧음 : 게시 및 수신 시 10밀리초 이내로 빠르게 응답
- SQS 메시지는 작아야 함
  - 전송된 메시지당 256KB 미만이어야 함
- SQS는 중복 메시지가 있을 수 있음
  - 대기열 서비스이므로 높은 처리량, 높은 볼륨 등이 있기 때문에
- SQS 대기열에서 더 많은 메시지가 있어서 처리량을 늘려야 하면 소비자를 추가하고 수평 확장을 수행해서 처리량을 개선할 수 있음
- 대기열의 길이가 특정 수준을 넘어가면 CloudWatch Alarm을 설정
  - 이 알람은 오토 스케일링 그룹의 용량을 X만큼 증가시킴
### SQS 보안
- 메시지를 보내고 생성함으로써 비행 중 암호화를 하고 KMS 키를 사용하여 미사용 암호화를 얻고 원한다면 클라이언트 측 암호화를 할 수도 있는데
- 이는 클라이언트가 자체적으로 암호화 및 암호 해독을 수행해야 함을 의미함
- SQS 에서 기본적으로 지원하는 것은 아님
- 액세스 제어를 위해 IAM 정책은 SQS API에 대한 액세스를 규제할 수 있고
- S3 버킷 정책과 유사한 SQS 액세스 정책도 있음
  - SQS 대기열에 대한 교차 계정 액세스를 수행하려는 경우나
  - SNS 혹은 Amazon S3 같은 다른 서비스가 SQS 대기열에 S3 이벤트 같은 것을 쓸 수 있도록 허용하려는 경우에 유용
### SQS 메시지 가시성 시간 초과(Message Visibility Timeout)
- 소비자가 메시지를 폴링하면 그 메세지는 다른 소비자에게 보이지 않게 됨
- 컨슈머가 ReceiveMessage 요청을 하면 대기열에서 메시지가 반환이되고 가시성 시간 초과가 시작됨
- 기본값으로 메시지 가시성 초과는 30초
  - 30초 동안 메시지가 처리되어야 함
- 동일한 혹은 다른 소비자가 메시지 요청 API를 호출하면 메시지가 반환되지 않음
- 시간 초과 기간 내에 또 다른 요청이 들어와도 메시지가 반환되지 않음
- 하지만 가시성 시간 초과가 경과되고 메시지가 삭제되이 낳았다면 메시지는 대기열에 다시 넣음
- 그럼 다른 소비자 또는 동일한 소비자가 또 ReceiveMessage API 호출을 하면 이전의 그 메시지를 또 받음
- 가시성 시간 초과 기간 내에 메시지를 처리하지 않으면 메시지가 두 번 처리될 수도 있다!
- 만약, 소비자가 메시지를 처리하고 있지만 시간이 더 필요하다면, 메시지를 처리하지 않아 가시성 시간 초과 기간을 벗어날 때를 위해
- ChangeMessageVisibility API 가 있음
  - 소비자가 메시지를 처리하는 데 시간이 더 필요하다는 것을 알고 있고, 해당 메시지를 두 번 처리하고 싶지 않다면
  - 소비자는 ChangeMessageVisibility API를 호출하여 SQS에 알려야 함
- 가시성 시간 초과 설정을 길게 하면 되는 거 아님?
  - 그렇게되면 소비자가 충돌했을 때 이 메시지가 다시 나타날 때까지(SQS 대기열에 보이기까지) 몇 시간이 걸림 -> 오래 걸림
  - 따라서 가시성 시간 초과는 애플리케이션에 합당한 것으로 설정되어야 하고,
  - 소비자는 시간이 조금 더 필요하다는 것을 알면 ChangeMessageVisibility API를 호출하도록 프로그래밍 해야 한다.
### SQS Long Polling
- 소비자가 대기열에 메시지를 요청하는데 대기열에 아무것도 없다면 메시지 도착을 기다리면 되는 것을 Long Polling 이라고 함
- Long Poolling 을 하는 이유
  - 지연 시간을 줄이기 위함
  - SQS로 보내는 API 호출 숫자를 줄이기 위함
- Long Polling 작동 방식
  - 소비자가 대기열에 폴링 - 최대 20초 동안 폴링 할 것
  - 메시지가 발생할 때 소비자가 여전히 롱 폴링 중이라면 자동적으로 그 메시지가 소비자에게 전송됨
  - 이때의 지연 시간은 짧아서 자동으로 최대한 빨리 받게 됨
- Long Polling 은 SQS로의 API 호출 숫자를 줄임
- 애플리케이션의 호율성과 대기 시간 증가
- SQS 대기열에 대한 API 호출 수를 최적화하고 지연 시간을 줄이는 방법은 ? Long Polling 구성하기
### SQS FIFO Queue
- 선입선출
- 대기열에 첫 번째로 도착한 메시지가 대기열을 떠날 때도 첫 번째가 되도록 대기열 내의 순서가 정렬된다
- 순서를 확실히 보장하기 때문에 SQS 대기열의 처리량에는 제한이 있음
  - 묶음이 아닐 경우에는 초당 300개의 메시지를 처리
  - 메시지를 묶음으로 보낸다면 그 처리량은 초당 3,000
- 중복을 제거하도록 해주는 SQS FIFO 대기열 기능도 존재
  - 정확히 한 번만 보낼 수 있도록 해줌
- 분리가 필요하거나 메시지의 순서를 유지할 필요가 있을 때 FIFO 대기열을 사용하면 됨
- SQS로 너무 많은 메시지를 보내지 않도록 처리량에 제한도 할 수 있다는 것도 중요
### SQS Auto Scaling Group (ASG)
- SQS 대기열과 오토 스케일링 그룹이 있을 때 ASG 내의 EC2 인스턴스에 메시지를 SQS 대기열에서 폴링
- 이는 오토 스케일링 그룹을 자동으로 대기열 크기에 따라 확장시키기 위함으로 CloudWatch 지표인 대기열 길이를 보고 결정할 수 있음
- ApproximateNumberOfMessages
  - 대기열에 몇 개의 메시지가 남아 있는지를 표시
  - 이를 기반으로 경보를 지정할 수 있음
  - 만약 이 지표가 1,000을 넘는 경우 1,000개의 메시지가 대기열에서 처리를 기다리고 있다는 뜻으로 처리에 지연이 발생하고 있음을 파악할 수 있음
  - 따라서 경보를 생성하여 1,000개의 메시지가 대기 중임을 경보를 통해 알리면
  - EC2 인스턴스가 충분하지 않음을 근거로 오토 스케일링 그룹에 확장 동작을 트리거함
  - 이렇게 하면 오토 스케일링 그룹에 더 많은 EC2 인스턴스가 추가되며 확장이 이루어져 메시지가 훨씬 더 빨리 처리됨
  - 동시에 SQS 대기열의 크기는 줄어들어 이에 대한 축소 또한 실행됨
- 예를 들어 애플리케이션이 두문 요청을 처리할때 모종의 이유로 특정 트랜잭션에 오류가 발생되면?
  - 데이터베이스에 바로 요청을 쓰는 경우에는 고객 트랜잭션이 유실되어 비즈니스에 좋지 못한 영향을 끼침
  - 이때 쓰기 대상 데이터베이스에서 SQS를 버퍼로 사용할 수 있다
- 데이터에비스에 바로 요청을 쓰는 대신 애플리케이션이 SQS 대기열에 먼저 쓰는 방법
  - 처리량 문제가 발생하지 않음
  - 애플리케이션에 요청이 전송되고 이 요청으 메시지로 대기열에 안착하는데 이는 곧 모든 트랜잭션, 즉 모든 요청이 SQS 대기열에 메시지로서 전달된다는 뜻
  - 유실되는 요청이 없어짐
  - 요청은 지속적으로 SQS 대기열에 저장
  - 여기서 또 다른 오토 스케일링 그룹으로 메시지를 대기열에서 제외할 수도 있음
- 이 패턴은 클라이언트에게 따로 데이터베이스에 쓰였다는 확인을 전송할 필요가 없을 때만 사용 가능함
- 하지만 SQS 대기열에 쓰기 작업이 일어났다는 것만으로도 결국 데이터베이스에 요청이 쓰일 테니 일종의 확인을 한 셈
- 분리나 급격히 증가한 로드 혹은 시간초과 등의 문제에서 신속한 스케일링이 필요한 경우에 SQS 대기열을 기억하자


## SNS
- 메시지 하나를 여러 수신자에게 보낼때 직접 통합(Direct integration)을 쓸 수 있는데
- 구매 서비스 애플리케이션에서 이메일 알림을 보내고 사기 탐지 서비스, 배송 서비스 그리고 SQS 대기열에도 메시지를 보낼 수 있음
- 하지만 수신 서비스를 새로 추가할 때마다 통합을 생성하고 작성해야 하므로 번거로울 수 있다
- 대신 Pub/Sub - 게시/구독 이라는 것을 사용하자
- Amazon SNS에서 event producer는 한 SNS topic에만 메시지를 보냄
- event receivers는 해당 topic 관련한 SNS 알림을 받으려는 사람
- 따라서 SNS topic 구독자는 해당 topic 으로 전송된 모든 메시지를 받게 됨
- 그리고 메시지를 필터링하는 기능을 사용하는 경우에도 메시지를 받을 수 있음
- 주제별 최대 구독자 수는 1,200만 이상
- 계정당 가질 수 있는 주제 수는 최대 10만 
- SNS에서 직접 이메일을 보낼 수도 있고
- SMS 및 모바일 알림을 보낼 수도 있다
- 지정된 HTTP 또는 HTTPS 엔드 포인트로 직접 데이터를 보낼 수도 있다
- SNS 는 SQS와 같은 특정 AWS 서비스와 통합하여 메시지를 대기열로 직접 보낼 수도 있고
- 메시지를 수신한 후 함수가 코드를 수행하도록 Lambda에 보내거나 Firehose 를 통해 데이터를 Amazon S3나 Redshift로 보낼 수도 있다
- SNS는 다양한 AWS 서비스에서 데이터를 수신하기도 함
- CloudWatch 경보, AutoScaling 그룹 알림, CloudFormation (State Chages), Budgets, S3 버킷, DMS, Lambda, DynamoDB, RDS ...
- AWS에서 알림이 발생하면 이러한 서비스가 지정된 SNS 주제로 알림을 보냄
- SNS How to publish
  - Topic Public (using the SDK)
    - Create a topic
    - Create a subscription (or many)
    - Publish to the topic
  - Direct Publish (for mobile apps SDK)
    - Create a platform application
    - Create a platform endpoint
    - Publish to the platform endpoint
    - 수신 가능 대상: Google GCM, Apple APNS, Amazon ADM...
### SNS + SQS: Fan Out
- 메시지를 여러 SQS 대기열에 보내고 싶은데 모든 SQS 대기열에 개별적으로 메시지를 보내면 문제가 생길 수 있다.
  - 애플리케이션이 중간에 비정상적으로 종료
  - 전달에 실패
  - SQS 대기열이 더 추가
- 이런 경우 Fan Out 패턴을 사용
- 일단 SNS 주제에 메시지를 전송한 후 원하는 수의 SQS 대기열이 이 SNS 주제를 구독
- 이 대기열들은 구독자로서 SNS로 들어오는 모든 메시지를 받음
- 이는 완전히 분리된 모델이며 데이터도 손실되지 않음
- SQS로 작업을 다시 시도할 수도 있고 데이터 지속성, 지연 처리도 수행 가능
- 이런 방식으로 SNS 주제를 구독하도록 더 많은 SQS 대기열을 추가할 수도 있음
- Fan Out 패턴을 사용하려면 SQS 액세스 정책에서 SNS 주제가 SQS 대기열에 쓰기 작업을 할 수 있도록 허용해야 함
- 리전 간 전달도 가능
- 한 리전의 SNS 주제에서 다른 리전의 SQS 대기열로 메시지를 보낼 수 있음
- Fan Out 패턴 활용
  - 여러 대기열에 동일한 S3 이벤트 알림을 보내고 싶을 때
    - S3 객체를 생성하여 S3 버킷에 이벤트 형성
    - 이 이벤트를 SNS 주제로 전송한 후 Fan Out 패턴으로 많은 SQS 대기열이 SNS 주제를 구독하도록 함
    - 물론 다른 유형의 애플리케이션, 이메일, Lambda 함수 등도 구독할 수 있음
    - 이런 식으로 팬아웃 덕분에 Amazon S3에서 발생하는 이벤트의 메시지가 여러 다른 목적지에 도달할 수 있게 함
  - 다른 아키텍처에서는 Kinesis Data Firehose (KDF)를 통해 SNS에서 Amazon S3로 직접 데이터를 전송할 수 있음
    - SNS를 KDF에 직접 연결하여 구매 서비스에서 데이터를 SNS 주제로 전송할 수 있음
    - 그런 다음 KDF에서 해당 정보를 수신하고 해당 KDF에서 Amazon S3 버킷으로 전달하거나 특정한 KDF 목적지로 어디든 전달할 수 있음
    - 이런 방식으로 SNS 주제의 메시지를 계속 이어가도록 확장할 수 있다
  - FIFO 주제에 적용
    - 생산자가 메시지 1, 2, 3, 4를 보내고 구독자는 1, 2, 3, 4의 순서로 메시지를 수신하는 SQS FIFO 대기열이 됨
    - 이 SNS FIFO는 SQS FIFO와 유사함
    - 메시지 그룹 ID에 따라 순서를 매기고 중복 제거 ID를 활용하거나 내용을 비교하여 중복 데이터를 제거
    - SQS FIFO 대기열을 FIFO SNS 주제의 구독자로 설정
    - 필요한 이유는?
      - SQS FIFO를 활용하여 팬아웃을 수행하려면 팬아웃, 순서, 중복 제거가 필요함
      - 구매 서비스가 데이터를 SNS FIFO 주제로 전달하고 두 개의 SQS FIFO 대기열로 팬아웃한 후,
      - 사기 탐지 서비스와 배송 서비스가 이 FIFO 대기열에서 데이터를 읽어 들임
  - 메시지 필터링
    - 메시지를 필터링하는 데 사용되는 JSON 정책
    - 주문에서 발주된 주문만 골라서 SQS 대기열을 만들고자 한다면
    - SQS 대기열이 SNS 주제를 구독하게 하고 JSON으로 필터링 정책을 적용


## Kinesis
- Kinesis를 활용하면 실시간 스트리밍 데이터를 손쉽게 수집하고 처리하여 분석할 수 있음
  - 실시간 데이터 : Application logs, Metrics, Website clickstreams, IoT telemetry data...
  - 데이터가 빠르게 실시간으로 생성된다면 모두 실시간 데이터 스트림으로 간주 가능
- Kinesis의 네가지 서비스
  - Kinesis Data Stream : 데이터 스트림을 수집하여 처리하고 저장
  - Kinesis Data Firehose : 데이터 스트림을 AWS 내부나 외부의 데이터 저장소로 읽어 들임
  - Kinesis Data Analytics : SQL 언어나 Apache Flink 를 활용하여 데이터 스트림을 분석
  - Kinesis Video Stream : 비디오 스트림을 수집하고 처리하여 저장
### Kinesis Data Stream
- 시스템에서 큰 규모의 데이터 흐름을 다루는 서비스
- 여러 개의 샤드로 구성되어 있고 각 샤드는 1번, 2번...N번까지 번호가 매겨짐 
  - (사전에 프로비저닝 - 시작할 때 스트림을 몇개의 샤드로 구성할 지 결정)
- 샤드는 데이터 수집률이나 소비율 측면에서 스트림의 용량을 결정
- 과정
  - 생산자는 데이터를 Kinesis Data Stream 으로 보냄(생산자: 애플리케이션, 데스크톱, 휴대전화...)
    - 레코드는 파티션 키와 최대 1MB 크기의 데이터 블롭으로 구성
    - 파티션 키는 레코드가 이용할 샤드를 결정하는 데 사용
    - 데이터 블롭은 값 자체를 의미
    - 생산자는 데이터를 스트림으로 보낼 때 초당 1MB를 전송하거나 샤드당 1초에 천 개의 메시지를 전송할 수 있음
    - 여섯 개의 샤드가 있다면 초당 6MB를 얻거나 총 6천 개의 메시지를 얻을 수 있음
  - 소비자가 생산자의 데이터를 사용
    - 소비자의 종류
      - SDK에 의존하거나 높은 수준에서는 Kinesis Client Library, KCL에 의존하는 애플리케이션
      - Kinesis 스트림에서 서버리스로 처리하려는 경우 Lambda 함수도 가능
      - Kinesis Data Firehose
      - Kinesis Data Analyics
    - 레코드 구성
      - 시퀀스 번호
      - 데이터 자체를 의미하는 데이터 블롭
    - 소비 유형
      - 샤드마다 초당 2MB의 처리량을 모든 소비자가 공유
      - 소비자마다 샤드당 1초에 2MB씩 받기(효율성을 높인 소비 팬아웃 방식)
- 특징
  - 보존 기간은 1일에서 365일 사이로 설정할 수 있음
  - 데이터가 일단 Kinesis로 들어오면 삭제할 수 없음(불변성)
  - 데이터 스트림으로 메시지를 전송하면 파티션 키가 추가되고 파티션 키가 같은 메시지들은 같은 샤드로 들어가게 되어 키를 기반으로 데이터를 정렬할 수 있음
  - 생산자는 SDK, Kinesis Producer Library (KPL), Kinesis Agent 를 사용하여 데이터를 전송할 수 있음
  - 소비자는 Kinesis Client Library (KCL)나 SDK를 써서 직접 데이터를 작성할 수 있음
  - AWS에서 관리하는 Lambda나 Kinesis Data Firehose, Kinesis Data Analytics를 활용할 수 있음
- Kinesis Data Stream 용량 유형
  - 프로비저닝 유형
    - 프로비저닝할 샤드 수를 정하고 API를 활용하거나 수동으로 조정
    - 각 샤드는 초당 1MB나 1천 개의 레코드를 받아들이고 출력량의 경우에는 각 샤드가 초당 2MB 를 받아들임
    - 샤드를 프로비저닝할 때마다 시간당 비용이 부과되므로 사전에 심사숙고해야함
  - 온디맨드 유형
    - 프로비저닝을 하거나 용량을 관리할 필요가 없음
    - 시간에 따라 언제든 용량이 조정됨
    - 기본적으로 초당 4MB 또는 초당 4천 개의 레코드를 처리
    - 이 용량은 지난 30일 동안 관측한 최대 처리량에 기반하여 자동으로 조정
    - 시간당 스트림당 송수신 데이터양(GB 단위)에 따라 비용이 부과됨
  - 사용량을 사전에 예측할 수 없다면 온디맨드 유형 선택
  - 사용량을 사전에 계획할 수 있다면 프로비저닝 유형 선택
- Kinesis Data Stream의 보안
  - IAM 정책을 사용하여 샤드를 생성하거나 샤드에서 읽어 들이는 접근 권한을 제어
  - HTTPS로 전송 중 데이터를 암호화할 수 있으며 미사용 데이터는 CMS로 암호화할 수 있음
  - 클라이언트 암호화 : 클라이언트 측에서 데이터를 암호화하거나 해독할 수 있음
    - 직접 데이터를 암호화하고 해독해야 하기 때문에 수행하기가 더 여러움 but 보안은 강화
  - Kinesis에서 VPC 엔드포인트를 사용할 수 있음
    - Kinesis에 인터넷을 거치지 않고 프라이빗 서브넷의 인스턴스에서 직접 손쉽게 접근할 수 있음
  - 모든 API 요청은 CloudTrail로 감시할 수 있음
### Kinesis Data Firehose
- 생산자에서 데이터를 가져올 수 있는 유용한 서비스이며, 생산자는 Kinesis Data Stream에서 본 무엇이든 될 수 있습니다.
- 애플리케이션, 클라이언트, SDK, KPL, Kinesis Agent, Kinesis Data Stream, 아마존 CloudWatch, AWS IoT 모두 Kinsis Data Firehose로 생산할 수 있음
- 데이터를 전송하면 Kinesis Data Firehose는 람다 기능을 활용해 데이터를 변환할지 선택할 수 있는데 이는 옵션임
- 일단 데이터를 변환하면 배치로 수신처에 쓸 수 있음
- Kinesis Data Firehose는 소스에서 데이터를 가져오는데 주로 Kinesis Data Stream이고 수신처에 데이터를 쓸 수 있음
- Kinesis Data Firehose 의 수신처 종류
  - AWS 수신처
    - 아마존 S3, 아마존 레드시프트
    - 여기에 데이터를 쓸 때는 먼저 아마존 S3에 데이터를 쓰면 Kinesis Data Firehose 가 복사 명령어를 내보냄
    - 이 복사 명령어가 아마존 S3의 데이터를 아마존 레드시프트로 복사
    - 아마존 ElasticSearch
  - 써드 파티 파트너 수신처
    - 데이터독, 스플렁크, 뉴렐릭, 몽고DB 등..
  - 자체 API
    - HTTP 엔드포인트가 있는 자체 API를 보유하고 있다면 Kinesis Data Firehose를 통해 커스텀 수신처로 데이터를 보낼 수 있음
- 데이터가 이러한 수신처로 전송되고 나면 우리에겐 두 가지 옵션이 있음
  - 모든 데이터를 백업으로 S3 버킷에 보내기
  - 수신처에 쓰이지 못한 데이터를 실패 S3 버킷에 보냄
- 정리
  - 관리가 필요하지 않으며 자동으로 용량 크기가 조정되고 서버리스이므로 관리할 서버가 없음
  - 레드시프트와 아마존 S3, ElasticSearch와 같은 AWS 수신처로 데이터를 보낼 수 있고 스플렁크, 몽고DB, 데이터독, 뉴렐릭 등 써드 파티 파트너로 보낼 수 있음
  - 어떤 HTTP 엔드포인트든 커스텀 수신처로도 보낼 수 있음
  - Kinesis Data Firehose를 통하는 데이터에 대해서만 비용을 지불하면 됨
  - 근 실시간으로 이루어짐
    - Kinesis Data Firehose에서 수신처로 데이터를 배치로 쓰기 때문
    - 전체 배치가 아닌 최소 60초 지연시간이 발생하거나 데이터를 수신처에 보내는 데 한 번에 적어도 1MB의 데이터가 있을 때까지 기다려야 함
    - 그렇기에 실시간 서비스가 아니라 실시간에 가까운 서비스
    - 여러 데이터 형식과 데이터 전환, 변환, 압축을 지원하며, 필요하면 람다를 활용해 자체적인 데이터 변환도 쓸 수 있음
- 시험
  - Kinesis Data Stream을 사용할 경우, Kinesis Data Firehose를 사용해야 한느 경우를 구분해야 하는 문제
  - Kinesis Data Stream
    - Kinesis Data Stream은 데이터를 대규모로 수집할 때 쓰는 스트리밍 서비스고 생산자와 소비자에 대해 커스텀 코드를 쓸 수 있음
    - 실시간으로 이루어지며 약 70ms 혹은 200ms 정도의 지연시간이 발생함.
    - 용량을 직접 조정할 수 있어 샤드 분할이나 샤드 병합을 통해 용량이나 처리량을 늘릴 수 있음
    - 제공한 용량만큼 비용을 지불, 데이터는 1일에서 365일간 저장
    - 여러 소비자가 같은 스트림에서 읽어 올 수 있고 반복 기능도 지원
  - Kinesis Data Firehose
    - 수집 서비스로 데이터를 아마존 S3나 레드시프트, ElasticSearch 써드 파티 파트너나 자체 HTTP로 스트리밍해줌
    - 완전 관리되며 서버리스이고 근 실시간으로 이뤄짐(near real-time)
    - 자동으로 용량 조정되어 관련해 걱정할 필요 없음
    - Kinsis Data Firehose를 통과하는 데이터에 대해서만 비용을 지불하면 됨
    - 데이터 스토리지가 없어 Kinesis Data Firehose의 데이터를 반복하는 기능은 지원되지 않음
### Kinesis와 SQS FIFO에 대한 데이터 정렬
- 트럭 1, 트럭 2 그리고 트럭 100까지 도로에 있고 GPS 위치를 주기적으로 AWS에 전송
  - 각 트럭의 순서대로 데이터를 소비해서 트럭의 이동을 정확하게 추적하고 그 경로를 순서대로 확인하려고 할 때 어떻게 `Kinesis`로 데이터를 전달할까?
    - 파티션 키를 사용하기
    - 파티션 키 값은 트럭 ID
    - 트럭 1은 트럭 1의 파티션 키를 전송하고 트럭 2는 트럭 2의 파티션 키를 전송
      - 같은 파티션 키를 지정하면 해당 키가 언제나 동일한 샤드로 전달
      - 추후 재 전송 할때도 동일한 파티션 키를 전송하므로 동일한 샤드로 이동함
    - Kinesis가 파티션 키를 해시해서 어느 샤드로 보낼지 결정.
  - SQS FIFO 에서는 어떻게 처리할까?
    - SQS 표준 방식에는 순서가 없음 따라서 SQS FIFO 라는 선입 선출 방식이 있음
    - 이 SQL FIFO의 그룹 ID를 사용하지 않으면 모든 메시지가 소비되는 방식은 보내진 순서에 따르며 소비자는 하나만 존재함
    - 트럭이 있다면 모든 트럭이 FIFO 대기열로 데이터를 보내더라도 소비자는 하나뿐
    - 만약 소비자 숫자를 스케일링하고 서로 연관된 메시지를 그룹화하려는 경우 그룹 ID를 사용할 수 있음 = Kinesis 파티션 키와 비슷
    - 그룹 ID를 사용하기
      - 그룹 ID를 사용하면 FIFO 대기열은 FIFO 내부에 두 개 그룹이 생기고 정의한 그룹마다 각각 소비자를 가질 수 있게 됨
      - 그룹 ID가 많을수록 소비자로 많아짐
  - Kinesis와 SQS FIFO의 차이점
    - Kinesis 샤드가 5개
      - Kinesis 데이터 스트림에서 평균적으로 가지는 값은 샤드당 트럭 20대
      - 해시 기능 덕분에 각 트럭은 하나의 샤드에 지정되고 해당 샤드에 계속 머물 것
      - 트럭 데이터는 각 샤드에 순서대로 정렬됨, 하지만 동시에 가질 수 있는 최대 소비자 개수는 5개
      - 샤드가 5개이고 샤드마다 하나의 소비자가 필요하기 때문
      - Kinesis 데이터 스트림은 샤드가 5개인 경우에 초당 최대 5MB의 데이터를 수신할 수 있으며 처리량이 많은 편
    - SQS FIFO 대기열이 1개
      - 샤드 및 파티션을 정의할 필요 없이 SQS FIFO 대기열이 하나
      - 트럭이 100대 있으므로 각 트럭 ID에 상응하는 그룹 ID를 100개 생성
      - 그룹 ID가 100개가 되고 소비자도 최대 100개...
      - 각 소비자가 특정한 그룹 ID와 연결됨
      - 최대 초당 300, 혹은 배치를 사용하면 3,000개의 메시지를 가짐
  - Kinesis vs SQS FIFO
    - SQS FIFO는 그룹 ID 숫자에 따른 동적 소비자 수를 원할 때 사용하면 좋은 모델
    - Kinesis 데이터 스트림을 사용할 경우는 예를 들면 트럭 10,000대가 많은 데이터를 전송하고 또 Kinesis 데이터 스트림에 샤드당 데이터를 정렬할 때

# SQS vs SNS vs Kinesis
## SQS
- SQS 에서는 소비자가 SQS 대기열에서 메시지를 요청해서 데이터를 가져오는(pull) 모델
- 따라서 데이터를 처리한 후 소비자가 대기열에서 삭제해서 다른 소비자가 읽을 수 없도록 해야 함
- 작업자나 소비자 수는 제한 없음 작업자와 소비자가 함께 소비하고 대기열에서 삭제하기 때문
- 또 관리된 서비스이므로 처리량을 프로비저닝할 필요가 없고 아주 빠르게 수백 수천 개의 메시지로 확장할 수 있음
- 순서를 보장하려면 FIFO 대기열 즉 선입선출 대기열을 활성화해야 함
- 각 메시지에 지연 기능이 있어 30초 등 일정 시간 뒤에 대기열에 나타나도록 할 수도 있음
## SNS
- 게시/구독 모델로 다수의 구독자에게 데이터를 푸시하면 메시지의 복사본을 받게 됨
- SNS 주제별로 1,250만 명의 구독자까지 가능, 데이터가 한 번 SNS에 전송되면 지속되지 않음
- 즉 제대로 전달되지 않는다면 데이터를 잃을 가능성이 있음
- 게시 구독 모델은 최대 10만 개의 주제로 확장 가능
- 처리량을 프로비저닝하지 않아도 되고 원한다면 SQS 와 결합할 수 있음
- 팬아웃 아키텍처 패턴을 이용하면 SNS와 SQS를 결합하거나 SNS FIFO 주제를 SQS FIFO 대기열과 결합할 수 있음
## Kinesis
- 두 가지 소비 모드가 있음
  - 소비자가 Kinesis로부터 데이터를 가져오는(pull) 표쥰 모드는 샤드당 2MB/s 속도를 지원
  - 향상된 팬아웃 유형의 소비 메커니즘에서는 Kinesis가 소비자에게 데이터를 푸시하며 샤드 하나에 소비자당 2MB/s 속도가 나옴
    - 처리량이 훨씬 높기 때문에 Kinesis 스트림에서 더 많은 애플리케이션 읽기가 가능함
- Kinesis 데이터 스트림에서는 데이터가 지속되기 때문에 데이터를 다시 재생할 수 있음
- 따라서 실시간 빅 데이터 분석, ETL 등에 활용됨
- 샤드 레벨에서 정할 수 있어 미리 Kinesis 데이터 스트림마다 원하는 샤드 양을 지정해야 함
- 샤드를 직접 확장해서 데이터가 언제 만료될지 정함 (현재 1에서 365일까지 데이터를 보존할 수 있음)
- 용량 모드에는 두 가지가 있음
  - 프로비저닝 용량 모드는 Kinesis 데이터 스트림으로부터 원하는 샤드 양을 미리 지정
  - 온디맨드 용량 모드에서는 샤드 수가 Kinesis 데이터 스트림에 따라 자동으로 조정